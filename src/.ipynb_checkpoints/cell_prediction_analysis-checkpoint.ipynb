{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPFL BIO 322 Project  \n",
    "### Gene Prediction based on Mouse brain single cell gene expression profiles\n",
    "\n",
    "### Authors:\n",
    "\n",
    "- Simon Lee (simon.lee@epfl.ch) \n",
    "- Léa Goffinet (lea.goffinet@epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "\n",
    "In an experiment on epigenetics and memory, Giulia Santoni (from the lab of Johannes Gr¨aff at\n",
    "EPFL) measured the gene expression levels in multiple cells of a mouse brain under three different\n",
    "conditions that we call KAT5, CBP and eGFP. In this challenge, the goal is to predict – as accurately\n",
    "as possible – for each cell the experimental condition (KAT5, CBP or eGFP) under which it was\n",
    "measured, given only the gene expression levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process\n",
    "import concurrent\n",
    "from multiprocessing import Pool\n",
    "import xgboost as xgb\n",
    "import glob\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/pb8cdz1d7055dx7_vljmm_1w0000gn/T/ipykernel_49123/1706260236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m     \"\"\"\n\u001b[1;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read raw data\n",
    "df = pd.read_csv('../data/train.csv.gz', compression='gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected single cell data is extremely sparse. Lets count to see how many non zero entries we actually have per column to get a glimpse of what might be important genes and what might not be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_column_headers = df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this cell only if you want to do filter and write out the counts of how many non zero columns are in each column to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this gets the counts of each column and drops the column accordingly\n",
    "# f = open('../data/counts.txt', 'w')\n",
    "# for gene in gene_column_headers:\n",
    "#     count = (df[gene] != 0).sum()\n",
    "    \n",
    "#     f.write('Counts of gene in cells {} : {} \\n'.format(gene, count))  # Uncomment if you want to generate text file with counts\n",
    "\n",
    "#     # new data generator: Takes 3 hrs to run!!\n",
    "#     # if count < 500:\n",
    "#     #     df = df.drop(columns=[gene])\n",
    "\n",
    "# # df.to_csv('../data/filtered_train.csv.gz, compression='gzip')\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_csv('../data/filtered_train.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the filtering process removed over 22,000 genes that were seen across less than 10% of the cells. Though the threshold is a hyperparameter we believe choosing a smaller hyperparameter will be a safer bet to not throw away useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Xkr4</th>\n",
       "      <th>Gm19938</th>\n",
       "      <th>Mrpl15</th>\n",
       "      <th>Lypla1</th>\n",
       "      <th>Tcea1</th>\n",
       "      <th>Rgs20</th>\n",
       "      <th>Atp6v1h</th>\n",
       "      <th>Rb1cc1</th>\n",
       "      <th>Pcmtd1</th>\n",
       "      <th>...</th>\n",
       "      <th>mt-Co3</th>\n",
       "      <th>mt-Nd3</th>\n",
       "      <th>mt-Nd4</th>\n",
       "      <th>mt-Nd5</th>\n",
       "      <th>mt-Cytb</th>\n",
       "      <th>CAAA01118383.1</th>\n",
       "      <th>Vamp7</th>\n",
       "      <th>Tmlhe</th>\n",
       "      <th>AC149090.1</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.190380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.293686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.839343</td>\n",
       "      <td>1.839343</td>\n",
       "      <td>2.190380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.190380</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.293686</td>\n",
       "      <td>CBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.861984</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>1.458439</td>\n",
       "      <td>1.291817</td>\n",
       "      <td>1.091771</td>\n",
       "      <td>0.841436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>KAT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.766762</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.012971</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.012971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.683511</td>\n",
       "      <td>eGFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.146434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.060763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.060763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664895</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.432486</td>\n",
       "      <td>CBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.840049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.132100</td>\n",
       "      <td>0.531053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.649491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531053</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.164235</td>\n",
       "      <td>eGFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>2.108581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644255</td>\n",
       "      <td>0.644255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.032877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312030</td>\n",
       "      <td>KAT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>3.108972</td>\n",
       "      <td>0.783343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783343</td>\n",
       "      <td>0.783343</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>1.379256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>1.518711</td>\n",
       "      <td>eGFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>2.025946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.650884</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.386459</td>\n",
       "      <td>1.456669</td>\n",
       "      <td>1.456669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.456669</td>\n",
       "      <td>2.025946</td>\n",
       "      <td>CBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>1.227544</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>...</td>\n",
       "      <td>2.245478</td>\n",
       "      <td>0.79137</td>\n",
       "      <td>1.227544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.108819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>KAT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>2.485066</td>\n",
       "      <td>0.550120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.163270</td>\n",
       "      <td>0.902971</td>\n",
       "      <td>1.163270</td>\n",
       "      <td>1.163270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550120</td>\n",
       "      <td>eGFP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Xkr4   Gm19938  Mrpl15    Lypla1     Tcea1     Rgs20  \\\n",
       "0              0  2.190380  0.000000     0.0  0.000000  1.293686  0.000000   \n",
       "1              1  2.861984  0.506726     0.0  0.000000  0.506726  1.458439   \n",
       "2              2  2.766762  0.629614     0.0  0.000000  1.012971  0.629614   \n",
       "3              3  2.146434  0.000000     0.0  0.000000  0.000000  0.000000   \n",
       "4              4  2.840049  0.000000     0.0  0.000000  0.000000  1.132100   \n",
       "...          ...       ...       ...     ...       ...       ...       ...   \n",
       "4995        4995  2.108581  0.000000     0.0  0.000000  0.000000  0.000000   \n",
       "4996        4996  3.108972  0.783343     0.0  0.000000  0.000000  0.783343   \n",
       "4997        4997  2.025946  0.000000     0.0  0.000000  0.000000  0.000000   \n",
       "4998        4998  1.227544  0.791370     0.0  0.000000  0.791370  0.000000   \n",
       "4999        4999  2.485066  0.550120     0.0  0.902971  0.000000  1.163270   \n",
       "\n",
       "       Atp6v1h    Rb1cc1    Pcmtd1  ...    mt-Co3   mt-Nd3    mt-Nd4  \\\n",
       "0     1.839343  1.839343  2.190380  ...  2.190380  0.00000  0.000000   \n",
       "1     1.291817  1.091771  0.841436  ...  0.000000  0.00000  0.000000   \n",
       "2     0.629614  0.000000  1.012971  ...  0.000000  0.00000  0.000000   \n",
       "3     1.060763  0.000000  1.060763  ...  0.664895  0.00000  0.000000   \n",
       "4     0.531053  0.000000  1.649491  ...  0.531053  0.00000  0.000000   \n",
       "...        ...       ...       ...  ...       ...      ...       ...   \n",
       "4995  0.000000  0.644255  0.644255  ...  1.312030  0.00000  0.000000   \n",
       "4996  0.783343  0.466491  1.379256  ...  0.466491  0.00000  0.000000   \n",
       "4997  0.000000  2.386459  0.000000  ...  2.650884  0.00000  2.386459   \n",
       "4998  0.791370  0.791370  0.791370  ...  2.245478  0.79137  1.227544   \n",
       "4999  0.902971  1.163270  1.163270  ...  0.000000  0.00000  0.000000   \n",
       "\n",
       "        mt-Nd5   mt-Cytb  CAAA01118383.1  Vamp7     Tmlhe  AC149090.1  labels  \n",
       "0     0.000000  0.000000        0.000000    0.0  0.000000    1.293686     CBP  \n",
       "1     0.000000  0.506726        0.000000    0.0  0.000000    0.506726    KAT5  \n",
       "2     0.000000  0.629614        0.000000    0.0  0.000000    1.683511    eGFP  \n",
       "3     0.000000  0.000000        0.000000    0.0  0.000000    2.432486     CBP  \n",
       "4     0.000000  0.000000        0.531053    0.0  0.000000    2.164235    eGFP  \n",
       "...        ...       ...             ...    ...       ...         ...     ...  \n",
       "4995  0.000000  1.032877        0.000000    0.0  0.000000    1.312030    KAT5  \n",
       "4996  0.000000  0.000000        0.000000    0.0  0.466491    1.518711    eGFP  \n",
       "4997  1.456669  1.456669        0.000000    0.0  1.456669    2.025946     CBP  \n",
       "4998  0.000000  2.108819        0.000000    0.0  0.000000    0.000000    KAT5  \n",
       "4999  0.550120  0.000000        0.550120    0.0  0.000000    0.550120    eGFP  \n",
       "\n",
       "[5000 rows x 9139 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for any null values incase we need to perform imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "check_nan = df.isnull().values.any()\n",
    "print(check_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_column_headers = df_filtered.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 XGBoost\n",
    "\n",
    "- Once with our filtered data\n",
    "- Also run with raw data to see if filtering has an effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation set using sklearn\n",
    "gene_column_headers_filtered = gene_column_headers[:-1]\n",
    "y = df_filtered['labels']\n",
    "X = df_filtered.iloc[:,:-1]\n",
    "\n",
    "# need to transform our labels from [KAT5, CBP, eGFP] -> [0,1,2] \n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a typical split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "training_data = {'X_train':X_train,'y_train':y_train,\n",
    "                'X_val': X_val,'y_val':y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 9137)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit function where it takes the sklearn and xgboost models and performs the boosted trees.\n",
    "# plots performance and accuracy as well\n",
    "\n",
    "def fit(model, training_data=training_data, epochs=300, label_gene = gene_column_headers_filtered):\n",
    "    # fitting to the sklearn model\n",
    "    print('Fitting model...')\n",
    "    model.fit(training_data['X_train'], training_data['y_train'])\n",
    "    print('Fitting done!')\n",
    "\n",
    "    # fitting the xboost library model\n",
    "    train = xgb.DMatrix(training_data['X_train'], label=training_data['y_train'])\n",
    "    test = xgb.DMatrix(training_data['X_test'], label=training_data['y_test'])\n",
    "    params = model.get_xgb_params()\n",
    "    metrics = ['mlogloss','merror']\n",
    "    params['eval_metric'] = metrics\n",
    "    evaluation = {}\n",
    "    evallist = [(test, 'test'),(train,'train')]\n",
    "    xgb_model = xgb.train(params, train, epochs, evallist, evals_result=evaluation,verbose_eval=100)\n",
    "\n",
    "    # Model reports\n",
    "    print('-- Model Report --')\n",
    "    print('XGBoost Accuracy: '+str(accuracy_score(model.predict(training_data['X_test']), training_data['y_test'])))\n",
    "    print('XGBoost F1-Score: '+str(f1_score(model.predict(training_data['X_test']),training_data['y_test'], average='micro')))\n",
    "    \n",
    "    # plotting the error curves for our loss functions\n",
    "    for m in metrics:\n",
    "        test_score = evaluation['test'][m]\n",
    "        train_score = evaluation['train'][m]\n",
    "        x = range(0, epochs)\n",
    "        plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "        plt.plot(x, test_score, label=\"Test\")\n",
    "        plt.plot(x, train_score, label=\"Train\")\n",
    "        \n",
    "        title_name = m + \" plot\"\n",
    "        plt.title(title_name)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(m)\n",
    "        lgd = plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # makes sure that the two array match so we can plot the feature importance\n",
    "    print(\"length of features list: {}\".format(len(gene_column_headers_filtered)))\n",
    "    print(\"length of feature importance vector {}\".format(len(model.feature_importances_)))\n",
    "\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters that can be adjusted in the final model\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, # play around with learning rate\n",
    "                    n_estimators=300, # play around with number of boosted trees built\n",
    "                    max_depth=9, # play around with tree depth\n",
    "                    objective='multi:softmax',  # I saw that using softmax or softprob is best for multi class classification\n",
    "                    nthread=4,\n",
    "                    num_class=3,\n",
    "                    seed=1 # seed is included for reproducibility\n",
    "                    )\n",
    "\n",
    "xgb_trained = fit(xgb_model, training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in test.csv.gz to assess model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv.gz', compression='gzip', usecols=gene_column_headers_filtered)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get it into dmatrix again\n",
    "X = test\n",
    "testing_data = xgb.DMatrix(data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xgb.DMatrix(training_data['X_test'], label=training_data['y_test'])\n",
    "pred = xgb_trained.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(training_data['y_val'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(training_data['y_val'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n",
    "# confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, ['KAT5', 'CBP', 'eGFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "plt.rcParams[\"figure.figsize\"] = [22,40]\n",
    "xgb.plot_tree(xgb_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [22,22]\n",
    "xgb.plot_importance(xgb_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters that can be adjusted in the final model\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, # play around with learning rate\n",
    "                    n_estimators=300, # play around with number of boosted trees built\n",
    "                    max_depth=9, # play around with tree depth\n",
    "                    objective='multi:softmax',  # I saw that using softmax or softprob is best for multi class classification\n",
    "                    nthread=4,\n",
    "                    num_class=3,\n",
    "                    seed=1 # seed is included for reproducibility\n",
    "                    )\n",
    "\n",
    "xgb_trained = fit(xgb_model, training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected alot of features aren't very important but lets still try running our classifier with our raw data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data. Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation set using sklearn\n",
    "y = df['labels']\n",
    "X = df.loc[:, df.columns != 'labels'] \n",
    "\n",
    "# need to transform our labels from [KAT5, CBP, eGFP] -> [0,1,2] \n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a typical split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "data = {'X_train':X_train,'y_train':y_train,\n",
    "                'X_test': X_val,'y_test':y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters that can be adjusted in the final model\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, # play around with learning rate\n",
    "                    n_estimators=300, # play around with number of boosted trees built\n",
    "                    max_depth=9, # play around with tree depth\n",
    "                    objective='multi:softmax',  # I saw that using softmax or softprob is best for multi class classification\n",
    "                    nthread=4,\n",
    "                    num_class=3,\n",
    "                    seed=1 # seed is included for reproducibility\n",
    "                    )\n",
    "\n",
    "xgb_trained = fit(xgb_model, training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train more different hyperparameter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xgb.DMatrix(training_data['X_test'], label=training_data['y_test'])\n",
    "pred = xgb_trained.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(training_data['y_test'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(training_data['y_test'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix, ['KAT5', 'CBP', 'eGFP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Sparse-Input Neural Networks\n",
    "\n",
    "- Once with our filtered data\n",
    "- Also run with raw data to see if filtering has an effect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "35cdeb169a3a070e0ef85dea5b2d3935a5fd9ad58668884b11eff71bff43ceff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
